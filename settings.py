ENCODING = 'utf-8'
OVERRIDE_FILES = False
SPACY_CORE = 'en_core_web_sm'

TASK1_PATH = 'task1_crawler/'
TASK1_OUTPUT_PATH = 'task1_crawler/output/'
TASK2_PATH = 'task2_tokenization/'
TASK3_PATH = 'task3_index/'
TASK4_PATH = 'task4_tf_idf/'

WORDS_FILENAME = 'words.txt'
TOKENS_FILENAME = 'tokens.txt'
SENTENCES_FILENAME = 'sentences.bin'
INVERTED_FILENAME = 'index.bin'

""" Task 2 """
# tokenize hardcode
TEXT_BEFORE_TAG = '<br class="cbt"'
TEXT_AFTER_TAG = '<div id="questions" class=" flush-left">'
CUT_FROM = ' views '
SPLIT_STR = 'min ago'

